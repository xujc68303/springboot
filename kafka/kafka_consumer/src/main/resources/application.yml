server:
  port: 8086

  tomcat:
    uri-encoding: utf-8

  servlet:
    session:
      timeout: 30m

spring:

  application:
    name: kafka-consumer

  profiles:
    active: dev

  datasource:
    type: com.alibaba.druid.pool.DruidDataSource
    druid:
      driver-class-name: com.mysql.cj.jdbc.Driver
      url: jdbc:mysql://localhost:3306/test?useUnicode=true&serverTimezone=Asia/Shanghai&characterEncoding=utf8
      username: root
      password:
      initial-size: 1
      max-active: 30
      min-idle: 1
      max-wait: 30000

  kafka:
    bootstrap-servers: 127.0.0.1:9092
    consumer:
      #earliest: 各分区下有已提交的偏移量时，从提交的偏移量开始消费，无提交的偏移量时，从头开始消费
      #latest: 各分区下有已提交的偏移量时，从提交的偏移量开始消费，无提交的偏移量时，消费新产生的该分区下的数据
      #none: topic各分区都存在已提交的偏移量时，从偏移量后开始消费，只要有一个分区不存在已提交的偏移量，则抛出异常
      auto-offset-reset: latest
      #自动提交
      enable-auto-commit: true
      #自动提交间隔
      auto-commit-interval: 100
      #反序列化
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      group-id: test_consumer-group

    listener:
      # 消费者数量
      concurrency: 1
      # 每一批拉取的数据被消费者监听器处理之后，距离上次提交时间大于TIME时提交，或者被处理record数量大于等于COUNT时提交
      ack-mode: COUNT_TIME
      missing-topics-fatal: false
